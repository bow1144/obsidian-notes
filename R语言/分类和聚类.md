- 加载数据
```
#加载BreastCancer数据集 
data(BreastCancer) 

#查看该数据集的前10个数据 
head(BreastCancer) 

#查看该数据集的维度信息 
dim(BreastCancer) 

#查看该数据集分类的种类 
levels(BreastCancer$Class)
```

- 删除缺失数据的行
```
#删除ID列将其赋值给dftemp 
dftemp <- BreastCancer[-1] 

#判断dftemp中有无缺失值的行 
dftemp[!complete.cases(dftemp),] 

#删除数据中有缺失值的行 
df<-na.omit(dftemp)
```

- 将数据分为训练集与测试集
```
#训练集占0.7,测试集占0.3 
train <- sample(nrow(df), 0.7*nrow(df)) # train是一个行号向量
df.train <- df[train,] 
df.validate <- df[-train,] 

# 利用 table函数查看测试集和训练集中恶性肿瘤和良性肿瘤所占比例
table(df.train$Class) 
table(df.validate$Class)
```

## 逻辑回归
```
# 利用glm()函数实现logisticRegression, 如果设置默认迭代次数,迭代次数过少可能不收敛
fit.logit <- glm(Class~., #以class为目标变量
	data=df.train, 
	family=binomial(), 
	control=list(maxit=100)) #迭代次数为100
summary(fit.logit)  #查看结果

#利用predict函数实现测试集预测概率,并存入prob 
prob <- predict(fit.logit, df.validate, type="response") 

#概率值大于0.5的被判定为malignant,否则判定为benign 
logit.pred <- factor(prob > .5, levels=c(FALSE, TRUE), labels=c("benign", "malignant")) 

#计算分类混淆矩阵 
logit.perf <- table(df.validate$Class, 
	logit.pred, 
	dnn=c("Actual", "Predicted")) 
logit.perf
```

## 决策树
```
library(rpart) 
set.seed(1234) 

#生成决策树 
dtree <- rpart(Class ~ ., 
	data=df.train, 
	method="class",  # 分类树
	parms=list(split="information"))  # 准则为信息增益

#绘制决策树,需要用到prp函数,绘制中参数的控制会引起绘制图形的变化. library(rpart.plot) 
prp(dtree, 
	type = 4,  #指定节点的显示方式（4 表示显示分支的概率分布）
	extra = 104,  #显示额外信息
	fallen.leaves = TRUE,  #使叶节点排列在同一水平线上，便于阅读
	main="Decision Tree") 
	
#利用生成的决策树进行预测 
dtree.pred <- predict(dtree, df.validate, type="class") 

#比较真实标注与预测值的差异,生成混淆矩阵 
dtree.perf <- table(df.validate$Class, 
	dtree.pred,
	dnn=c("Actual", "Predicted"))
dtree.per
```

## 随机森林
```
library(randomForest)
set.seed(1234)

fit.forest <- randomForest(Class~., 
	data=df.train, 
	importance=TRUE
)

importance(fit.forest, type=2)
forest.pred <- predict(fit.forest, df.validate) 
forest.perf <- table(df.validate$Class, 
	forest.pred, 
	dnn=c("Actual", "Predicted")) 
forest.perf
```

## 支持向量机
```
library(e1071)
set.seed(1234)

it.svm <- svm(Class~., data=df.train)
fit.svm # 查看训练情况

svm.pred <- predict(fit.svm, df.validate)
svm.perf <- table(na.omit(df.validate)$Class, svm.pred, dnn=c("Actual", "Predicted")) 

svm.perf
```

## 层次聚类
```
#将距离矩阵赋值给distxy 
distxy <- dist(dataFrame) 
#利用hclust函数层次聚类 
hClustering <- hclust(distxy) 
#绘制层次聚类结果 
plot(hClustering)

#聚类为3类 
clusterCut <- cutree(hClustering, 3) 
#查看聚类结果 
clusterCut
```

## K-means聚类
```
dataFrame <- data.frame(x,y) 
kmeansObj <- kmeans(dataFrame,centers=3) 
names(kmeansObj)
```